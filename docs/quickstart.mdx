---
title: Quick Start
description: Implement hybrid search over Postgres in under five minutes
---

<Note>
  This guide will show you how to run Retake in a development environment. For
  assistance in deploying to production, please [contact our
  team](http://calendly.com/philippemnoel).
</Note>

In this quickstart, we will implement hybrid search over a [Kaggle e-commerce dataset](https://www.kaggle.com/datasets/mukuldeshantri/ecommerce-fashion-dataset),
which contains 30,000 rows of products. Here is a simplified version of what the dataset looks like:

| BrandName   | Description                                                    | SellPrice | Category          |
| ----------- | -------------------------------------------------------------- | --------- | ----------------- |
| Fratini     | solid polyester blend wide neck womens regular top - off white | 74        | Westernwear-Women |
| Zinc London | stripes polyester sweetheart neck womens dress - black         | 849       | Westernwear-Women |
| Kraus       | wide ankle length cotton womens jeans - light blue             | 2449      | Westernwear-Women |

To follow along with this tutorial, you can optionally [download the full CSV file](https://www.kaggle.com/datasets/mukuldeshantri/ecommerce-fashion-dataset/download?datasetVersionNumber=1)
and upload it to a Postgres table.

## (Optional) Upload CSV to Postgres

This tutorial uses Neon, a serverless Postgres provider that makes it very easy to create Postgres tables and upload
CSVs, but you can use any Postgres service. First, we connect to our Neon instance using `psql`:

```bash
psql -h pg.neon.tech
```

Once inside `psql`, we can create a table and upload the CSV file:

```sql
CREATE TABLE products (
  id integer,
  BrandName text,
  Details text,
  Sizes text,
  MRP text,
  SellPrice text,
  Discount text,
  Category text
);

\copy products FROM '/path/to/FashionDataset.csv' DELIMITER ',' CSV HEADER;
```

The last step is to create a primary key. All tables must have a primary key to integrate with Retake:

```sql
ALTER TABLE products ADD COLUMN product_id SERIAL PRIMARY KEY;
```

## Install Retake

<Info>**Prerequisite** Docker and Docker Compose must be installed.</Info>

Download the [docker compose file](https://raw.githubusercontent.com/getretake/retake/main/docker-compose.yml) and run:

```bash
docker compose up
```

This spins up the Retake engine, which is responsible for executing search queries and storing search data.
Next, install the Retake SDK in your Python or Typescript environment.

<CodeGroup>

```bash Python
pip install retakesearch
```

```bash Typescript
npm install retake-search
```

</CodeGroup>

## Index Postgres

<Info>
  **Prerequisite** Please ensure that you have [enabled logical
  replication](/setup) in your Postgres database.
</Info>

Next, we use the Retake Python SDK to tell the Retake engine what table(s) we wish to search over.

The `Index.add_source` function integrates Retake directly with Postgres. As long as the Retake engine is running, this
function only needs to be run once.

<CodeGroup>

```python Python
from retakesearch import Client, Index, Database, Table

# When the Retake engine is run locally,
# this is the default API key/URL
client = Client(
  api_key="retake-test-key",
  url="http://localhost:8000"
)

# Provide your Postgres database credentials here
database = Database(
    host="***",
    user="***",
    password="***",
    dbname="***",
    port=5432,
)

# Provide the table name and columns you wish to search over here
table = Table(
    name="products"
    columns=["BrandName", "Details", "Sizes", "SellPrice", "Discount", "Category"]
    transform={"mapping": {"SellPrice": "integer"}}
)

# Create an index
index = client.create_index("products")

# Populate the index with data from your table
# Note: The table must have a primary key
index.add_source(database, table)
```

```typescript Typescript
import { Client, Database, Table, Search } from "retake-search";

// When the Retake engine is run locally,
// this is the default API key/URL
const client = new Client("retake-test-key", "http://localhost:8000");

// Provide your Postgres database credentials here
const database = new Database({
  host: "***",
  user: "***",
  password: "***",
  dbName: "***",
  port: 5432,
});

// Provide the table name and columns you wish to search over here
const columns = ["column_to_search"];
const table = new Table({
  table: "table_name",
  columns: columns,
});

// Create an index
const index = client.create_index("table_name");

// Populate the index with data from your table
// Note: The table must have a primary key
index.addSource(database, table);
```

</CodeGroup>

### From Memory

Data stored outside of Postgres can also be added to an index.

<CodeGroup>

```python Python
documents = [{"key": "value"}]
ids = ["id1"]

index.upsert(
  documents=documents,
  ids=ids
)
```

```typescript Typescript
const documents = [{ key: "value" }];
const ids = ["id1"];

index.upsert(documents, ids);
```

</CodeGroup>

## Execute a Search

Inside our application, we are ready to write and execute our first search query.

<CodeGroup>

```python Python
from retakesearch import Search

# This executes a full-text (BM25) search
bm25_search_query = Search().query("match", questions="Who am I?")
response = index.search(bm25_search_query)

print(response)
```

```typescript Typescript
import { Search } from "retake-search";
import { matchQuery } from "retake-search/helpers";

// This executes a full-text (BM25) search
const bm25Query = Search().query(matchQuery("column_to_search", "my query"));
const response = index.search(bm25Query);

print(response);
```

</CodeGroup>

Note that Retake's `Search` query builder is a forked version of the
[high-level OpenSearch client](https://opensearch.org/docs/latest/clients/python-high-level) for Python and
[elastic-builder](https://elastic-builder.js.org/docs/) for Typescript.
Please refer to the [search guide](search/overview) for the essentials of writing search queries.

## Congrats!

You've successfully executed a neural search query over your Postgres database.
