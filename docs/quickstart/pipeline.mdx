---
title: "Create Your First Pipeline"
description: "Build your first vector pipeline in under five minutes"
---

In this tutoral we will build a pipeline to sync documents stored in AWS Aurora Postgres with their embeddings,
stored in Pinecone. As you will see, Retake supports a variety of sources and sinks and
you can substitute any source or sink with a few lines of code.

For this example, let's imagine that we are a developer building a chatbot at Babylon, an e-commerce website.
In Postgres, we have a table called `faqs`, which contains two columns: `questions` and `answers`.
We wish to combine each question and answer, embed it, and store it in Pinecone.

### Installation

<Info>
  **Prerequisite** You should have installed Python (version 3.8 or higher).
</Info>

<CodeGroup>

```bash terminal
pip install retake
```

</CodeGroup>

### Import SDK

In a new Python file, we import the Retake SDK and all necessary classes:

```bash main.py
from retake import Source, Embedding, Sink, Target, Pipeline
```

### Create a `Source`

`Source` is the database where inputs/documents are stored.
In this example, `Source` is an AWS Aurora Postgres database. You can find
other sources [here](/concepts/source).

```bash main.py
# Replace with your database connection credentials
source = Source.Postgres(
    user="username",
    database="dbname",
    host="host"
    password="***",
    port=5432
)
```

### Create an `Embedding`

`Embedding` specifies the embedding model we wish to use. Retake [provides wrappers](/concepts/embedding) around most popular embedding models
and you can also bring your own.

```bash main.py
model = Embedding.SentenceTransformer(model="all-MiniLM-L6-v2")
```

### Create a `Sink`

`Sink` specifies where we want to store our vectors. In this example, `Sink` is Pinecone. You can find
a list of all available sinks [here](/concepts/sink).

```bash main.py
# Replace with your sink connection credentials
sink = Sink.Pinecone(
    api_key="***",
    environment="asia-southeast1-gcp"
)
```

### Create a `Target`

`Target` specifies the index or collection within our sink where we want to store our vectors. You can find
a list of all available targets [here](/concepts/target).

```bash main.py
target = Target.Pinecone(
    index_name="faqs",
    namespace="question_answer_embedding"
)
```

### Create a `Pipeline`

`Pipeline` defines your entire vector data stream, from source to sink.

```bash main.py
pipeline = Pipeline(
    source=source,
    embedding=model,
    sink=sink,
    target=target,
)
```

That's it! Now that your pipeline is created, continue to the next section to see how to send batch and
real-time updates through your pipeline.
